{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter [0] to continue and [1] to exit:\n",
      "0\n",
      "Enter product name:\n",
      "iphone 11\n",
      "\n",
      "\n",
      "Websites you can compare your product from\n",
      "[1] Flipkart\n",
      "[2] Amazon\n",
      "[3] Croma\n",
      "[4] Ajio \n",
      "\n",
      " More websites coming soon! \n",
      "\n",
      "\n",
      "Start Comparing? [Y/N]:\n",
      "Y\n",
      "\n",
      "\n",
      "\n",
      "Cool let's start then!\n",
      "Let's start scraping flipkart......\n",
      "\n",
      "\n",
      "https://www.flipkart.com/search?q=iphone+11&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=a067f372-6249-4a2a-acec-701c123d265a.MOBFWQ6BXGJCEYNY.SEARCH&ppt=None&ppn=None&ssid=uscekaeh680000001627168878820&qH=f6cdfdaa9f3c23f3\n",
      "APPLE iPhone 11 (Black, 64 GB)\n",
      "₹49,999\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "Now Let's scrape Amazon.....\n",
      "\n",
      "Image Link: https://m.media-amazon.com/images/I/71i2XhHU3pL._AC_UY218_.jpg\n",
      "\n",
      "Name: New Apple iPhone 11 (64GB) - Black \n",
      "Product Link:  https://www.amazon.in/s?k=iphone+11&ref=nb_sb_noss\n",
      "Price: ₹48,999\n",
      "\n",
      "\n",
      "\n",
      "Now Let's scrape Croma.........\n",
      "\n",
      "Image Link: https://media.croma.com/image/upload/f_auto,q_auto,d_Croma%20Assets:no-product-image.jpg,h_212,w_212/v1605264356/Croma%20Assets/Communication/Mobiles/Images/9001728606238.png\n",
      "\n",
      "Product Link: https://www.croma.com/apple-iphone-11-64gb-rom-4gb-ram-mhdf3hn-a-purple-/p/230110\n",
      "Name: Apple iPhone 11 (64GB ROM, 4GB RAM, MHDF3HN/A, Purple)\n",
      "\n",
      "Price: ₹52,900.00\n",
      "\n",
      "\n",
      "\n",
      "Now Let's scrape Ajio.........\n",
      "\n",
      "https://assets.ajio.com/medias/sys_master/root/20210312/KTkt/604bc34baeb2696981852615/chumbak_pink_owl_print_iphone_11_pro_max_mobile_case.jpg\n",
      "Name: Owl Print iPhone 11 Pro Max Mobile Case\n",
      "Product Not Found!\n",
      "\n",
      "\n",
      "\n",
      "The best price for the iphone11 is:\t\n",
      "48999.0\n",
      "\n",
      "\n",
      "\n",
      "Enter [0] to continue and [1] to exit:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Set options according to the browser you use\n",
    "# Get all info from the link below\n",
    "#https://www.selenium.dev/documentation/en/getting_started_with_webdriver/browsers/\n",
    "options = webdriver.FirefoxOptions()\n",
    "\n",
    "#uncomment the below code if you don't want a browser window to open\n",
    "# options.add_argument('--headless') \n",
    "\n",
    "flag = 0\n",
    "cchc = ''\n",
    "\n",
    "#will contain the peices of all websites and show the best price accordingly\n",
    "final_price_list = []\n",
    "\n",
    "def inputData():\n",
    "    proItem = input(\"Enter product name:\\n\")\n",
    "    itemName = proItem.replace(\" \",\"+\")\n",
    "    \n",
    "    print(\"\\n\\nWebsites you can compare your product from\\n[1] Flipkart\\n[2] Amazon\\n[3] Croma\\n[4] Ajio \\n\\n More websites coming soon! \\n\\n\")\n",
    "    cchc == input(\"Start Comparing? [Y/N]:\\n\")\n",
    "        \n",
    "    if cchc == 'Y' or 'y':\n",
    "        print(\"\\n\\n\\nCool let's start then!\")\n",
    "        flipkart(itemName)\n",
    "    else:\n",
    "        exit(1)\n",
    "        \n",
    "\n",
    "#Flipkart\n",
    "def flipkart(itemName):\n",
    "    print(\"Let's start scraping flipkart......\")\n",
    "    itemName = itemName\n",
    "    flipurl = f'https://www.flipkart.com/search?q={itemName}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "    headers = {\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0'\n",
    "    }\n",
    "\n",
    "    #scrape the main pro_list page of item\n",
    "    req = requests.get(flipurl,headers=headers)\n",
    "    soup = BeautifulSoup(req.content,'lxml')\n",
    "\n",
    "    try:\n",
    "\n",
    "        #main list\n",
    "        pro_list = soup.find_all('div',class_='_2kHMtA')\n",
    "\n",
    "        #will contain links of all product in the list\n",
    "        proLink = []\n",
    "\n",
    "        for i in pro_list:\n",
    "            for link in i.find_all('a',href=True):\n",
    "                proLink.append(flipurl + link['href'])\n",
    "\n",
    "\n",
    "        #scrape data from particular item\n",
    "        itemLink = proLink[0]\n",
    "\n",
    "        req = requests.get(itemLink,headers=headers)\n",
    "        soup = BeautifulSoup(req.content,'lxml')\n",
    "        image = soup.find_all('div',class_=\"CXW8mj _3nMexc\")\n",
    "\n",
    "        for name in soup.find_all('span',class_=\"B_NuCI\"):\n",
    "            pro_name = name.text.strip()\n",
    "        for price in soup.find_all('div',class_=\"_30jeq3 _16Jk6d\"):\n",
    "            pro_price = price.text.strip()\n",
    "        for img in image:\n",
    "            pro_image = img.get('src')\n",
    "\n",
    "        #append the price scraped in float form\n",
    "        temp_pro_price = pro_price.replace(\"₹\",\"\")\n",
    "        final_pro_price = float(temp_pro_price.replace(\",\",\"\"))\n",
    "        final_price_list.append(final_pro_price)\n",
    "        \n",
    "        print(\"\\n\")    \n",
    "        print(itemLink)\n",
    "        print(pro_name)\n",
    "        print(pro_price)\n",
    "        print(pro_image)\n",
    "        print(\"\\n\\n\\nNow Let's scrape Amazon.....\\n\")\n",
    "        amazon(itemName)\n",
    "    ################\n",
    "\n",
    "    except:\n",
    "        #main list\n",
    "        pro_list = soup.find_all('div',class_='_1xHGtK _373qXS')\n",
    "\n",
    "        #will contain links of all product in the list\n",
    "        proLink = []\n",
    "\n",
    "        for i in pro_list:\n",
    "            for link in i.find_all('a',href=True):\n",
    "                proLink.append(flipurl + link['href'])\n",
    "\n",
    "\n",
    "        #scrape data from particular item\n",
    "        itemLink = proLink[0]\n",
    "\n",
    "        req = requests.get(itemLink,headers=headers)\n",
    "        soup = BeautifulSoup(req.content,'lxml')\n",
    "        image = soup.find_all('div',class_=\"CXW8mj _3nMexc\")\n",
    "\n",
    "        for name in soup.find_all('span',class_=\"G6XhRU\"):\n",
    "            pro_name = name.text.strip()\n",
    "        for price in soup.find_all('div',class_=\"_30jeq3 _16Jk6d\"):\n",
    "            pro_price = price.text.strip()\n",
    "    #     for img in image:\n",
    "    #         pro_image = img.get('src')\n",
    "\n",
    "        print(\"\\n\")    \n",
    "        print(itemLink)\n",
    "        print(pro_name)\n",
    "        print(pro_price)\n",
    "    #     print(pro_image)\n",
    "        print(\"\\n\\n\\nNow Let's scrape Amazon.....\\n\")\n",
    "        amazon(itemName)\n",
    "    \n",
    "\n",
    "#amazon\n",
    "def amazon(itemName):\n",
    "    itemName = itemName\n",
    "    amazon_url = f'https://www.amazon.in/s?k={itemName}&ref=nb_sb_noss'\n",
    "    headers = {\n",
    "        'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0'\n",
    "    }\n",
    "\n",
    "    #scrape the main pro_list page of item\n",
    "    req = requests.get(amazon_url,headers=headers)\n",
    "    soup = BeautifulSoup(req.content,'lxml')\n",
    "\n",
    "    #list of all the products on the newUrl\n",
    "    pro_list = soup.find_all('div',{'data-component-type':'s-search-result'})\n",
    "    try:\n",
    "        prod = pro_list[0]\n",
    "\n",
    "        imageTag = prod.find('div',class_='a-section aok-relative s-image-fixed-height')\n",
    "        prodImage = imageTag.find('img')\n",
    "        prodImageLink = prodImage['src']\n",
    "        print(\"Image Link:\",prodImageLink)\n",
    "\n",
    "        atag = prod.h2.a\n",
    "        prodName = atag.text\n",
    "\n",
    "        # prodUrl = amazon_url + atag.find('a',href=True)\n",
    "\n",
    "        #prod price\n",
    "        price = prod.find('span',class_=\"a-price\")\n",
    "        amazonPrice = price.find('span',class_=\"a-offscreen\").text\n",
    "        \n",
    "        #append the price scraped in float form\n",
    "        temp_pro_price = amazonPrice.replace(\"₹\",\"\")\n",
    "        final_pro_price = float(temp_pro_price.replace(\",\",\"\"))\n",
    "        final_price_list.append(final_pro_price)\n",
    "\n",
    "        print(\"\\nName:\",prodName)\n",
    "        # print(\"URL:\\n\",prodUrl)\n",
    "        print(\"Product Link: \",amazon_url)\n",
    "        print(\"Price:\",amazonPrice)\n",
    "        time.sleep(2)\n",
    "        print(\"\\n\\n\\nNow Let's scrape Croma.........\\n\")\n",
    "        croma(itemName)\n",
    "    except:\n",
    "        print(\"Product not found!\")\n",
    "        print(\"\\n\\n\\nNow Let's scrape Croma.........\\n\")\n",
    "        croma(itemName)\n",
    "        \n",
    "        \n",
    "        \n",
    "def croma(itemName):\n",
    "    itemName = itemName\n",
    "    croma_base_url = 'https://www.croma.com'\n",
    "    croma_url = f'https://www.croma.com/search/?text={itemName}'\n",
    "    driver = webdriver.Firefox(executable_path=\"D:\\\\geckodriver-v0.28.0-win64\\\\geckodriver.exe\",options=options)\n",
    "    headers = {\n",
    "        'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0'\n",
    "    }\n",
    "\n",
    "    driver.get(croma_url)\n",
    "\n",
    "    soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "    #list of all the products on the newUrl\n",
    "    pro_list = []\n",
    "    pro = soup.findAll('div',class_='content-wrap')\n",
    "    for j in pro:\n",
    "        for i in j.findAll('ul',class_='product-list'):\n",
    "    #         print(i)\n",
    "            for k in i.findAll('li',class_='product-item'):\n",
    "                pro_list.append(k)\n",
    "\n",
    "    try:\n",
    "        prod = pro_list[0]\n",
    "\n",
    "        imageTag = prod.find('div',class_='product-img')\n",
    "        prodImage = imageTag.find('img')\n",
    "        prodImageLink = prodImage['src']\n",
    "        print(\"Image Link:\",prodImageLink)\n",
    "\n",
    "        atag = prod.h3.a\n",
    "        prodLink = croma_base_url + atag['href']\n",
    "        print(\"\\nProduct Link:\",prodLink)\n",
    "\n",
    "        name = prod.h3.text\n",
    "        print(\"Name:\",name)\n",
    "\n",
    "        cromaPrice = prod.find('span',class_='amount').text\n",
    "        \n",
    "        #append the price scraped in float form\n",
    "        temp_pro_price = cromaPrice.replace(\"₹\",\"\")\n",
    "        final_pro_price = float(temp_pro_price.replace(\",\",\"\"))\n",
    "        final_price_list.append(final_pro_price)\n",
    "        \n",
    "        print(\"\\nPrice:\",cromaPrice)\n",
    "        print(\"\\n\\n\\nNow Let's scrape Ajio.........\\n\")\n",
    "        ajio(itemName)\n",
    "    except:\n",
    "        print(\"Product not found!\")\n",
    "        print(\"\\n\\n\\nNow Let's scrape Ajio.........\\n\")\n",
    "        ajio(itemName)\n",
    "\n",
    "        \n",
    "        \n",
    "def ajio(itemName):\n",
    "    itemName = itemName\n",
    "    ajio_base_url = 'https://www.ajio.com/'\n",
    "    ajio_url = f'https://www.ajio.com/search/?text={itemName}'\n",
    "    driver = webdriver.Firefox(executable_path=\"D:\\\\geckodriver-v0.28.0-win64\\\\geckodriver.exe\",options=options)\n",
    "    headers = {\n",
    "        'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0'\n",
    "    }\n",
    "\n",
    "    driver.get(ajio_url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "    pro_list = []\n",
    "    pro = soup.findAll('div',class_='ReactVirtualized__Grid items')\n",
    "    for j in pro:\n",
    "        for i in j.findAll('div',class_='ReactVirtualized__Grid__innerScrollContainer'):\n",
    "    #         print(i)\n",
    "            for k in i.find('div',class_='item rilrtl-products-list__item item'):\n",
    "                pro_list.append(k)\n",
    "\n",
    "    try:\n",
    "        prod = pro_list[0]\n",
    "\n",
    "        imageTag = prod.find('div',class_='imgHolder')\n",
    "        prodImage = imageTag.find('img')\n",
    "        prodImageLink = prodImage['src']\n",
    "        print(prodImageLink)\n",
    "\n",
    "        name = prod.find('div',class_='name')\n",
    "        ajioName = name.text\n",
    "        print(\"Name:\",ajioName)\n",
    "\n",
    "        ajioPrice = prod.find('span',class_='price').text\n",
    "        \n",
    "        #append the price scraped in float form\n",
    "        temp_pro_price = ajioPrice.replace(\"₹\",\"\")\n",
    "        final_pro_price = float(temp_pro_price.replace(\",\",\"\"))\n",
    "        final_price_list.append(final_pro_price)\n",
    "        \n",
    "        print(\"\\nPrice:\",ajioPrice)   \n",
    "        price = ajioPrice\n",
    "        bestBuy(itemName)\n",
    "    except:\n",
    "        print(\"Product Not Found!\")   \n",
    "        bestBuy(itemName)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "def bestBuy(itemName):\n",
    "    itemName = itemName\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"The best price for the %s is:\\t\"%(itemName.replace('+','')))\n",
    "    print(min(final_price_list))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "while flag != 1:\n",
    "    flag = int(input(\"Enter [0] to continue and [1] to exit:\\n\"))\n",
    "    if flag == 0:\n",
    "        inputData()\n",
    "        \n",
    "    else:\n",
    "        exit(1)\n",
    "        \n",
    "    flag = int(input(\"Enter [0] to continue and [1] to exit:\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
